<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>RustFest Paris Workshop: Fastware</title>
    
    <meta name="description" content="">
    
    <meta itemprop="name" content="RustFest Paris Workshop: Fastware">
    
    
    <meta name="og:title" content="RustFest Paris Workshop: Fastware">
    
        <meta name="image" content="http://troubles.md/floppies.png">
        <meta name="og:image" content="http://troubles.md/floppies.png">
       <meta name="og:url" content="http://troubles.md/posts/rustfest-2018-workshop/">
    <meta name="og:site_name" content="RustFest Paris Workshop: Fastware">
    <meta name="og:type" content="article">
    
    <meta name="article:tag" content="">
    <link rel="stylesheet" type="text/css" href="http://troubles.md/css/style.css">
    <link rel="stylesheet" type="text/css" href="http://troubles.md/css/syntax.css">
    <script async>
        window.onload = function() {
            var possibilities = [
                 "A high-level view of low-level code",  "Writing words and reading DWORDS",  "A blog about bits and the frobbing thereof", 
            ];

            document.getElementById('subtitle').innerHTML = ' - ' + possibilities[Math.floor(possibilities.length * Math.random())];
        };
    </script>
</head>

<body>

<header>
    
    <a href="http://troubles.md/" class="title"><strong>troubles.md</strong></a>
    <p id="subtitle" class="subtitle"> - A high-level view of low-level code</p>
    
    
    
    <a href="http://troubles.md/index.xml" style="color:#777;float: right;">
        <strong>
            <svg
                xmlns="http://www.w3.org/2000/svg"
                width="16"
                height="16"
                viewBox="0 0 24 24"
                fill="none"
                stroke="currentColor"
                stroke-width="2"
                stroke-linecap="round"
                stroke-linejoin="round"
                class="feather feather-rss"
            >
                <path d="M4 11a9 9 0 0 1 9 9">
                </path>
                <path d="M4 4a16 16 0 0 1 16 16">
                </path>
                <circle cx="5" cy="19" r="1">
                </circle>
            </svg>
        </strong>
    </a>
</header>


<div class="content">
  <h1>RustFest Paris Workshop: Fastware <aside></aside></h1>
  

<blockquote>
<p>&ldquo;In almost every computation a great variety of arrangements for the succession of the processes is possible, and various considerations must influence the selection amongst them for the purposes of a Calculating Engine. One essential object is to choose that arrangement which shall tend to reduce to a minimum the time necessary for completing the calculation.&rdquo;</p>

<h3 id="ada-lovelace-1843">Ada Lovelace, 1843</h3>
</blockquote>

<h2 id="prerequisites">Prerequisites</h2>

<p>You should get these from your package manager where possible, but if you don&rsquo;t have a package manager installed then you can download them from the linked websites. Your package manager will be <a href="https://chocolatey.org/">choco</a> on Windows, <a href="https://brew.sh/">homebrew</a> on macOS, and on Linux it could be one of <code>apt-get</code>, <code>pacman</code>, <code>rpm</code>, <code>nix</code>, <code>cron</code>+<code>wget</code>, your secretary logging into your computer and downloading unsigned binaries while you sleep, etc.</p>

<ul>
<li>You&rsquo;ll need <a href="https://www.rust-lang.org/">Rust</a> to compile the code, of course.</li>
<li>The sample code for this is <a href="https://github.com/Vurich/rustfest-perf-workshop">here</a>.</li>
<li>To compare results we can use <code>cargo-benchcmp</code>, just run <code>cargo install cargo-benchcmp</code> to get it.</li>
<li>To generate performance traces you&rsquo;ll need <a href="http://valgrind.org/">Valgrind</a>, this requires macOS or Linux. If you&rsquo;re on Windows then you can use my Valgrind traces, see below.</li>
<li>To view the results you can use <a href="https://kcachegrind.github.io/html/Home.html">KCachegrind</a>.</li>
</ul>

<p>You&rsquo;ll probably have seen <code>perf</code>+<code>flamegraph</code> recommended before by <a href="http://troubles.md/posts/rust-optimization/">certain very smart and handsome fellows</a> but I&rsquo;ve actually had more luck with <code>callgrind</code> (included in Valgrind). You can try to use <code>perf</code> but although it can give very good outputs for some programs it&rsquo;s quite inconsistent. Also, using <code>callgrind</code> means you can use KCachegrind, which is the best thing since sliced bread. In the linked article I said that Valgrind was scary, but that was one of my patented Uninformed Opinions&trade;. It&rsquo;s actually very intuitive and, honestly, easier to use than the &ldquo;simple&rdquo; solution of using <code>perf</code>.</p>

<h2 id="finding-our-slow-sections">Finding our slow sections</h2>

<p>It&rsquo;s often said<sup class="footnote-ref" id="fnref:often-said"><a href="#fn:often-said">1</a></sup> that the slowest code is that which has been optimised without benchmarks. You wouldn&rsquo;t expect your code to work if you never ran it, so why should you expect it to be fast if you never benchmarked it? Writing good benchmarks is a bit of an art, because it&rsquo;s really easy to accidentally write benchmarks that make your code seem fast, when really the compiler is applying some optimisations that work in the side-effect-free world of the benchmark but can no longer get applied when you put it out into the wild.</p>

<p>You should have a few different kinds of benchmarks:</p>

<ol>
<li>Ones that operate on real-world data - if you spend all your time optimising but your users never see that speedup then what was the point of doing all that work in the first place?</li>
<li>Ones that exercise degenerate cases to make sure that your code isn&rsquo;t fast in the general case but incredibly slow in edge-cases.</li>
<li>Ones that exercise real-world cases in confinement, this can help pinpoint where your code is choking.</li>
</ol>

<p>You can see where I added the benchmarks in <a href="https://github.com/Vurich/rustfest-perf-workshop/commit/f839ff3cd76343e7371eec73de61997fa000f1eb">this commit</a> in the sample code repo. I&rsquo;ve heavily commented the benchmarks so you can see my thinking, and I highly recommend you read the comments and the code in that commit to get an idea of what a decent benchmark suite looks like. It&rsquo;s not perfect, more and better benchmarks could be written, but the point is that our language has very few primitives (function calls, variables, assigment, literals) and so we need benchmarks that exercise each of those.</p>

<p>Probably you already know <a href="https://doc.rust-lang.org/1.16.0/book/benchmark-tests.html">how to run benchmarks in Rust</a>, but doing so isn&rsquo;t actually terribly useful in isolation. Benchmarks alone are essentially meaningless, since they are affected by everything from the current PC setup to the other currently-running programs. Their power comes in comparison.</p>

<p>If you haven&rsquo;t already, you need to make sure that you&rsquo;re using the nightly release of Rust, since the stable release doesn&rsquo;t allow you to run benchmarks. If you&rsquo;re using <a href="https://rustup.rs/"><code>rustup</code></a>, this is simple - just do <code>rustup override set nightly</code>. If you&rsquo;re not using <code>rustup</code>, then use <code>rustup</code>. Sorry, it&rsquo;s really the only convenient way to use nightly Rust.</p>

<p>To get a baseline benchmark, you can output the results of <code>cargo bench</code> to a file. On Linux and macOS you can just run <code>cargo bench &gt; baseline.bench</code>. On each change you can output the new benchmarks to a new file by running <code>cargo bench &gt; new.bench</code>, then compare the two with <code>cargo benchcmp baseline.bench new.bench</code>. If you do it now, without making any changes, you should get something that looks like the following:</p>
<div class="highlight"><pre class="chroma"><code class="language-text" data-lang="text">name                           baseline.bench ns/iter  new.bench ns/iter  diff ns/iter  diff %  speedup 
benches::parse_deep_nesting    52,923                  53,618                      695   1.31%   x 0.99 
benches::parse_literals        34,167                  34,623                      456   1.33%   x 0.99 
benches::parse_many_variables  182,052                 180,939                  -1,113  -0.61%   x 1.01 
benches::parse_nested_func     36,798                  37,222                      424   1.15%   x 0.99 
benches::parse_real_code       4,578                   4,574                        -4  -0.09%   x 1.00 
benches::run_deep_nesting      2,705                   2,722                        17   0.63%   x 0.99 
benches::run_many_variables    42,622                  42,193                     -429  -1.01%   x 1.01 
benches::run_nested_func       4,563                   4,698                       135   2.96%   x 0.97 
benches::run_real_code         141,153                 141,211                      58   0.04%   x 1.00 </code></pre></div>
<p>You&rsquo;ll notice that even when you run the exact same code twice you can still get slightly different results. You shouldn&rsquo;t trust speedups of less than 2% unless you can very reliably reproduce them.</p>

<p>So, where do we start? Well, that&rsquo;s what our trusty friend Valgrind is for. Valgrind is an execution framework that allows plugins to analyse a compiled program at quite a deep level. It ships with tools to <a href="http://valgrind.org/docs/manual/mc-manual.html">detect memory safety bugs</a>, to <a href="http://valgrind.org/docs/manual/hg-manual.html">report possible deadlocks and race conditions</a> and - most importantly for us - to <a href="http://valgrind.org/docs/manual/cl-manual.html">analyse the time taken by individual functions</a>. It can&rsquo;t produce output that&rsquo;s very useful to humans without some help, however. Specifically, it needs debuginfo enabled. For release builds (<code>cargo build --release</code>) you can add that to the <code>Cargo.toml</code> like so:</p>
<div class="highlight"><pre class="chroma"><code class="language-toml" data-lang="toml"><span class="p">[</span><span class="nx">profile</span><span class="p">.</span><span class="nx">release</span><span class="p">]</span>
<span class="nx">debug</span> <span class="p">=</span> <span class="kc">true</span></code></pre></div>
<p>We need it for benchmarks, however. For that <code>cargo</code> uses the <code>bench</code> profile, and so we need to add the following to <code>Cargo.toml</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-toml" data-lang="toml"><span class="p">[</span><span class="nx">profile</span><span class="p">.</span><span class="nx">debug</span><span class="p">]</span>
<span class="nx">debug</span> <span class="p">=</span> <span class="kc">true</span></code></pre></div>
<p>This is added to the sample project already (see <a href="https://github.com/Vurich/rustfest-perf-workshop/commit/24a8fab60674dbc70b2ad18df8baba3e2edace65">this commit</a>). If you run <code>cargo bench</code> it will first build the benchmarking binary and then run it, displaying the path on stdout. When I run <code>cargo bench</code> it looks like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-text" data-lang="text">jef@jef-pc ~/D/G/V/rustfest&gt; cargo bench
   Compiling rustfest v0.1.0 (file:///home/jef/Documents/GitHub/Vurich/rustfest)
    Finished release [optimized] target(s) in 11.84s
     Running target/release/deps/rustfest-5c3dd55c20998644

running 9 tests
test benches::parse_deep_nesting   ... bench:      53,041 ns/iter (+/- 18,369)
test benches::parse_literals       ... bench:      34,433 ns/iter (+/- 5,025)
test benches::parse_many_variables ... bench:     185,630 ns/iter (+/- 36,507)
test benches::parse_nested_func    ... bench:      38,114 ns/iter (+/- 6,402)
test benches::parse_real_code      ... bench:       4,758 ns/iter (+/- 842)
test benches::run_deep_nesting     ... bench:       2,793 ns/iter (+/- 243)
test benches::run_many_variables   ... bench:      46,430 ns/iter (+/- 7,715)
test benches::run_nested_func      ... bench:       5,050 ns/iter (+/- 597)
test benches::run_real_code        ... bench:     152,798 ns/iter (+/- 46,472)

test result: ok. 0 passed; 0 failed; 0 ignored; 9 measured; 0 filtered out</code></pre></div>
<p>You can see that it displays the binary path on the third line, under <code>Running</code>. You can then run callgrind on this binary. For me this is <code>target/release/deps/rustfest-5c3dd55c20998644</code> but for you it could be something else, so use the output of <code>cargo bench</code> on your machine to see what the binary&rsquo;s name is.</p>

<blockquote>
<h3 id="important">Important!</h3>

<p>The binary&rsquo;s name will change when you change your code, as it&rsquo;s based on a hash of the source code and cargo&rsquo;s build parameters. Therefore it&rsquo;s very important to rerun <code>cargo bench</code> and run callgrind on the <em>new</em> binary name. Otherwise you&rsquo;ll be running it on the old binary and it will look like nothing has changed!</p>
</blockquote>

<h2 id="contents">Contents:</h2>

<ul>
<li><a href="#exercise-1">Exercise 1</a></li>
<li><a href="#exercise-2">Exercise 2</a></li>
<li><a href="#exercise-3">Exercise 3</a></li>
<li><a href="#exercise-4-intermediate-and-advanced-only">Exercise 4</a></li>
<li><a href="#further-work-1">Further work 1</a></li>
<li><a href="#further-work-2">Further work 2</a></li>
<li><a href="#further-work-3-advanced-only">Further work 3</a></li>
</ul>

<h1 id="exercise-1">Exercise 1</h1>

<p>If you&rsquo;re on a platform that Valgrind supports, you can follow the next steps to get a trace. Otherwise, you can use <a href="https://gist.githubusercontent.com/Vurich/5fc8d700ceaa85c0b185eb493a3d5125/raw/28894cfd8869b377fbb96e7a0a4f1c9e204a213b/callgrind.out.6359">my trace</a>. To run callgrind, execute Valgrind with <code>--tool=callgrind</code> on the benchmark binary. In order to make the benchmark binary actually run the benchmarks (by default it will run tests) you have to additionally pass <code>--bench</code> as an argument to the binary itself, like so:</p>
<div class="highlight"><pre class="chroma"><code class="language-text" data-lang="text">valgrind --tool=callgrind target/release/deps/rustfest-5c3dd55c20998644 --bench</code></pre></div>
<p>Callgrind actually has lots of options which you can see with <code>--help</code>, and they&rsquo;re really useful for debugging slowness within functions (as opposed to which functions are slow), but for now we&rsquo;ll just run it with the defaults. This will generate a file with a name like <code>callgrind.out.1234</code> where <code>1234</code> is a unique number for each run of callgrind. Run KCachegrind (it&rsquo;s a GUI program, so you probably don&rsquo;t want to start it from the command-line) and open the generated <code>callgrind.out</code> file. You should see something that looks like so:</p>

<p><img src="/rustfest-2018-workshop/kcachegrind.png" alt="KCachegrind's home screen" title="KCachegrind's home screen" /></p>

<p>This is probably pretty overwhelming. We can whittle down the functions to just our code by typing the name of our project (if you&rsquo;re using the sample project then this will be <code>rustfest</code>) into the search bar on the left. If we look at the list of functions that take the most time, we can see that after the generated <code>main</code> function the most time is spent in <code>eval</code>. Probably you guessed this, what with it being one of only two functions in our module, but hey, it&rsquo;s nice to get confirmation. Let&rsquo;s click on <code>eval</code> and see what its cost centers are. In the bottom-right, you&rsquo;ll see the list of functions called by <code>eval</code> in order of their total cost - these are called the &ldquo;callees&rdquo;. You can see a visualisation of the callees in a tree-like structure by clicking &ldquo;callee map&rdquo; at the top, but depending on your tolerance for soulless coloured rectangles the amount of use you can get from this may vary. In the list of callees, you can see that a <em>lot</em> of time is spent in <code>HashMap::clone</code> and <code>HashMap::drop</code><sup class="footnote-ref" id="fnref:rawtable"><a href="#fn:rawtable">2</a></sup>.  Essentially, we keep creating new <code>HashMap</code>s and then destroying them again:</p>

<p><img src="/rustfest-2018-workshop/kcachegrind-callees.png" alt="`eval`'s callees with `HashMap::clone` and `HashMap::drop` at the top" title="`eval`'s callees with `HashMap::clone` and `HashMap::drop` at the top" /></p>

<p>So where in <code>eval</code> are we cloning hashmaps? If we look at the source code, the answer is obvious:</p>
<div class="highlight"><pre class="chroma"><code class="language-rust" data-lang="rust"><span class="k">pub</span><span class="w"> </span><span class="k">fn</span> <span class="nf">eval</span><span class="p">(</span><span class="n">program</span>: <span class="nc">Ast</span><span class="p">,</span><span class="w"> </span><span class="n">variables</span>: <span class="kp">&amp;</span><span class="nc">mut</span><span class="w"> </span><span class="n">HashMap</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span><span class="w"> </span><span class="n">Value</span><span class="o">&gt;</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="nc">Value</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">    </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="w">    </span><span class="k">match</span><span class="w"> </span><span class="n">program</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">        </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="w">        </span><span class="n">Call</span><span class="p">(</span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="n">arguments</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">            </span><span class="kd">let</span><span class="w"> </span><span class="n">func</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">eval</span><span class="p">(</span><span class="o">*</span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="n">variables</span><span class="p">);</span><span class="w">
</span><span class="w">
</span><span class="w">            </span><span class="k">match</span><span class="w"> </span><span class="n">func</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">                </span><span class="n">Function</span><span class="p">(</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="n">body</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">                    </span><span class="c1">// Start a new scope, so all variables defined in the body of the
</span><span class="c1"></span><span class="w">                    </span><span class="c1">// function don&#39;t leak into the surrounding scope.
</span><span class="c1"></span><span class="w">                    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">new_scope</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variables</span><span class="p">.</span><span class="n">clone</span><span class="p">();</span><span class="w">
</span><span class="w">                    </span><span class="c1">//       Clone here ^---------------^
</span><span class="c1"></span><span class="w">
</span><span class="w">                    </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="w">                </span><span class="p">}</span><span class="w">
</span><span class="w">                </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="w">            </span><span class="p">}</span><span class="w">
</span><span class="w">        </span><span class="p">}</span><span class="w">
</span><span class="w">        </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="w">    </span><span class="p">}</span><span class="w">
</span><span class="w"></span><span class="p">}</span></code></pre></div>
<p>If we look at the callees for <code>clone</code> and <code>drop</code> by double-clicking on them we can see that the <code>HashMap</code> is spending a lot of time recursively cloning and dropping its elements. This is because not only is the <code>HashMap</code> heap-allocated, but so are its elements. <code>String</code> is a heap-allocated string that must be allocated, cloned and deallocated, and <code>Value</code> contains <code>Vec</code>s and <code>String</code>s - both heap-allocated. These values are all immutable and so we don&rsquo;t actually need owned, heap-allocated versions of these. There are a couple of optimisations that you can apply here, and I&rsquo;ve seperated them into beginner, intermediate and advanced.</p>

<h2 id="beginner">Beginner</h2>

<p>Convert our uses of <code>String</code> to be <code>Rc&lt;String&gt;</code>. This means that the clone and drop are just adding and subtracting 1 to the reference count, respectively. Run the benchmarks before and after making this change and use <code>cargo benchcmp</code> to verify that this has made an improvement.</p>

<h2 id="intermediate">Intermediate</h2>

<p>Same as above, but notice that <code>Rc&lt;String&gt;</code> actually has <em>two</em> heap allocations - the <code>Rc</code> just points to a <em>pointer</em> to the actual string data. Figure out if there&rsquo;s a way to avoid this. Hint: <code>Rc</code>&rsquo;s type parameter is <code>?Sized</code>.</p>

<h2 id="advanced">Advanced</h2>

<p>Do these strings need to be allocated on the heap at all? Combine actually has <a href="https://docs.rs/combine/3.3.0/combine/parser/range/fn.recognize.html">an API for zero-copy parsing</a>. It requires ensuring that the input can have pointers constructed to it - not possible if you&rsquo;re parsing from an iterator over bytes, for example. To ensure this you can add the following to the parser definition:</p>
<div class="highlight"><pre class="chroma"><code class="language-diff" data-lang="diff"><span class="gh">diff --git a/src/lib.rs b/src/lib.rs
</span><span class="gh">index 359915d..6db1190 100644
</span><span class="gh"></span><span class="gd">--- a/src/lib.rs
</span><span class="gd"></span><span class="gi">+++ b/src/lib.rs
</span><span class="gi"></span><span class="gu">@@ -91,7 +91,8 @@ pub fn eval(program: Ast, variables: &amp;mut HashMap&lt;String, Value&gt;) -&gt; Value {
</span><span class="gu"></span> }
 
 parser! {
<span class="gd">-    pub fn expr[I]()(I) -&gt; Ast where [I: combine::Stream&lt;Item = char&gt;] {
</span><span class="gd"></span><span class="gi">+    pub fn expr[&#39;a, I]()(I) -&gt; Ast where [
</span><span class="gi">+        I: combine::Stream&lt;Item = char, Range = &amp;&#39;a str&gt; +
</span><span class="gi">+        combine::RangeStreamOnce
</span><span class="gi">+    ] {
</span><span class="gi"></span>         use combine::parser::char::*;
         use combine::*;
</code></pre></div>
<p>I&rsquo;ll leave it to you to figure out the rest.</p>

<h1 id="exercise-2">Exercise 2</h1>

<p>Benchmark your code before and after making the changes above and compare the results with <code>cargo benchcmp</code>. Did it help? If so, how much by?</p>

<p>Even after making cloning our strings cheaper, we still do a lot of clones of values that are expensive to duplicate. We call <code>clone</code> on <code>Ast</code> and <code>Value</code>, both of which can contain <code>Vec</code>s and <code>Box</code>s - expensive to clone. Let&rsquo;s try to make those clones a little cheaper.</p>

<p>A cheap way to avoid clones is as above - use <code>Rc</code>. It is not necessarily a good thing, though. For a start, it&rsquo;s less ergonomic - only allowing immutable access. It&rsquo;s not necessarily faster in all cases either, since it adds an extra heap allocation and it means that dropping the value incurs a branch. Also, although <code>Rc</code> supports weak references it won&rsquo;t actually drop the value until all weak references have been destroyed - a possible source of memory leaks. <code>&amp;</code> pointers do not have this issue - although the compiler gives them special powers, at runtime they&rsquo;re just integers. Both can be used to avoid clones.</p>

<h2 id="beginner-1">Beginner</h2>

<p>We take an owned <code>Ast</code> as an argument to <code>eval</code>, which requires cloning the whole <code>Ast</code> every time we call <code>eval</code> again in the loop - this isn&rsquo;t necessary. We can take a borrowed <code>Ast</code> (<code>&amp;Ast</code>) and only clone the parts that we need. This should be faster than cloning the entire <code>Ast</code> on the chance that we need part of it as an owned value.</p>

<h2 id="intermediate-1">Intermediate</h2>

<p>What other clones are unnecessary? Most of our code is pure and only requires immutable access. However, we still clone the <code>Value</code>s in our scope every time we access them. Is there a way around this?</p>

<h2 id="advanced-1">Advanced</h2>

<p>Same as above, but note that most of <code>Value</code> is actually very cheap to clone. What can we do to take advantage of this fact?</p>

<h1 id="exercise-3">Exercise 3</h1>

<p>Again, make sure to run benchmarks to ensure you&rsquo;re making your code faster and not slower.</p>

<p>Check KCachegrind again - just underneath <code>clone</code> and <code>drop</code> then next most time-consuming function is <code>insert</code>. This is because Rust&rsquo;s default implementation of <code>HashMap</code> is not as fast as it could be - by design.</p>

<p>The reasoning behind this is best illustrated with an example. Let&rsquo;s say that we&rsquo;re selling flapjacks on the internet and we want to keep a mapping from customer name to address, in order to know where to send their delicious flapjacks<sup class="footnote-ref" id="fnref:flapjacks"><a href="#fn:flapjacks">3</a></sup>. Since we&rsquo;re a small business that has yet to reach <a href="https://www.youtube.com/watch?v=b2F-DItXtZs">Web Scale</a> we&rsquo;ve decided to just use an in-memory <code>HashMap</code> like so:</p>
<div class="highlight"><pre class="chroma"><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="nc">ServerState</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">    </span><span class="n">customers</span>: <span class="nc">HashMap</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span><span class="w"> </span><span class="nb">String</span><span class="o">&gt;</span><span class="p">,</span><span class="w">
</span><span class="w"></span><span class="p">}</span></code></pre></div>
<p>Except that the way that <code>HashMap</code> is implemented is to seperate the storage into some number of &ldquo;buckets&rdquo;, and so when you insert or retrieve from the <code>HashMap</code> you first find the bucket that it&rsquo;s in and then iterate over that bucket until you find the entry with the right key<sup class="footnote-ref" id="fnref:hashmap"><a href="#fn:hashmap">4</a></sup>. It looks something like this:</p>
<div class="highlight"><pre class="chroma"><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="nc">HashMap</span><span class="o">&lt;</span><span class="n">K</span><span class="p">,</span><span class="w"> </span><span class="n">V</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">    </span><span class="n">buckets</span>: <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="w"> </span><span class="n">V</span><span class="p">)</span><span class="o">&gt;&gt;</span><span class="p">,</span><span class="w">
</span><span class="w"></span><span class="p">}</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">impl</span><span class="o">&lt;</span><span class="n">K</span>: <span class="nc">Hash</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">Eq</span><span class="p">,</span><span class="w"> </span><span class="n">V</span><span class="o">&gt;</span><span class="w"> </span><span class="n">HashMap</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">    </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="w">
</span><span class="w">    </span><span class="k">fn</span> <span class="nf">get</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span><span class="w"> </span><span class="n">k</span>: <span class="kp">&amp;</span><span class="nc">K</span><span class="p">)</span><span class="w"> </span>-&gt; <span class="nb">Option</span><span class="o">&lt;&amp;</span><span class="n">V</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">bucket</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">hash</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="bp">self</span><span class="p">.</span><span class="n">buckets</span><span class="p">.</span><span class="n">len</span><span class="p">();</span><span class="w">
</span><span class="w">
</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="o">&amp;</span><span class="p">(</span><span class="k">ref</span><span class="w"> </span><span class="n">existing_k</span><span class="p">,</span><span class="w"> </span><span class="k">ref</span><span class="w"> </span><span class="n">v</span><span class="p">)</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="o">&amp;</span><span class="bp">self</span><span class="p">.</span><span class="n">buckets</span><span class="p">[</span><span class="n">bucket</span><span class="p">]</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">existing_k</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">                </span><span class="nb">Some</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="w">
</span><span class="w">            </span><span class="p">}</span><span class="w">
</span><span class="w">        </span><span class="p">}</span><span class="w">
</span><span class="w">
</span><span class="w">        </span><span class="nb">None</span><span class="w">
</span><span class="w">    </span><span class="p">}</span><span class="w">
</span><span class="w"></span><span class="p">}</span></code></pre></div>
<p>If you&rsquo;re an attacker trying to take down this innocent flapjack website and you can manipulate which bucket your customer name goes into, you can simply put all of your entries into the <em>same</em> bucket. This means that every new insertion or retreival to that one bucket is extremely slow, because it has to do much more comparisons than you normally would have to. The default <code>HashMap</code> used in Rust has two defences against this. Firstly, it initialises the hashing algorithm with a random seed, which means that because you don&rsquo;t know the initial hasher state you can&rsquo;t run the hashing algorithm many times on your own computer, find some customer names that would go into the same bucket, and then send those to the server. Second, the hashing algorithm is cryptographically secure. This means that there is no way to guess the initial state by just running the hasher many times, measuring how the output changes, and then deriving the state with maths. The default hashing algorithm is actually pretty fast, but is bad on small keys (like the short variable names in our programs). To improve performance we can use <code>FnvHash</code> from the <a href="https://crates.io/crates/fnv"><code>fnv</code></a> crate.</p>

<h2 id="beginner-2">Beginner</h2>

<p>Just add <code>FnvHashMap</code> to your crate, and check the benchmarks.</p>
<div class="highlight"><pre class="chroma"><code class="language-rust" data-lang="rust"><span class="k">extern</span><span class="w"> </span><span class="k">crate</span><span class="w"> </span><span class="n">fnv</span><span class="p">;</span><span class="w">
</span><span class="w">
</span><span class="w"></span><span class="k">use</span><span class="w"> </span><span class="n">fnv</span>::<span class="n">FnvHashMap</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">HashMap</span><span class="p">;</span></code></pre></div>
<h2 id="intermediate-2">Intermediate</h2>

<p>There are other &ldquo;fast hashmaps&rdquo; for Rust, like <a href="https://crates.io/crates/fxhash"><code>fxhash</code></a>. Which one is faster for these inputs?</p>

<h2 id="advanced-2">Advanced</h2>

<p>Apart from error messages, there&rsquo;s not really a reason to store the full name of the variable. We could memoize the hash of the variable name and then use that to key a <code>HashMap</code> with the identity function as the hashing algorithm. There doesn&rsquo;t seem to be an implementation of <code>IdentityHashMap</code> on <a href="https://crates.io/">crates.io</a> but it&rsquo;s easy enough to write.</p>

<h1 id="exercise-4-intermediate-and-advanced-only">Exercise 4 (Intermediate and advanced only)</h1>

<p>Although we made cloning the scope a lot cheaper, we still clone it in cases that are not necessary. For example, if we call a function with no arguments that doesn&rsquo;t define any internal variables, we don&rsquo;t need to clone the scope at all. We can avoid that by either passing a reference to an owned <code>HashMap</code> if possible, and an immutable reference otherwise. If it turns out that we need to clone the hashmap then we can replace the reference with an owned <code>HashMap</code> and mutate it from there. The standard library has a type to make this easy: <a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code>Cow</code></a>.</p>

<h2 id="intermediate-3">Intermediate</h2>

<p>Use <code>std::borrow::Cow</code> to avoid cloning the scope unless absolutely necessary.</p>

<h2 id="advanced-3">Advanced</h2>

<p>Explore the use of <a href="https://github.com/orium/rpds">persistent data structures</a> to maximise sharing. Do they help?</p>

<h1 id="further-work-1">Further work 1</h1>

<p>If you did the beginner or intermediate tasks for the previous exercises, why not try going back and doing the task a level above? If you did the advanced level, are there any more optimisations that you could apply to this? If so, implement them and see if they improve your results.</p>

<h1 id="further-work-2">Further work 2</h1>

<p>Try doing this same process on one of your own projects. Add debuginfo to the benchmarks, run it with <code>valgrind --tool=cachegrind /path/to/benchmarks --bench</code> and then open the results in KCachegrind. See if there&rsquo;s some way to reduce unnecessary copies, unnecessary work, and/or unnecessary allocation. Good targets for optimisation are virtual machines, image processing libraries and games. For games, though, if you&rsquo;re using a game engine then your traces might show most of your time taken in the engine&rsquo;s code and not yours.</p>

<h1 id="further-work-3-advanced-only">Further work 3 (Advanced only)</h1>

<p>Most modern languages don&rsquo;t operate directly on the AST of their program, they compile to bytecode first. One important thing to notice about this language is that (because <code>if</code> statements aren&rsquo;t lazily evaluated and there are no loops) it&rsquo;s impossible for a program to conditionally define a variable. Therefore if a variable is defined and accessed within the same function you can just access it by index instead of by name. Unfortunately, because our language is <a href="https://stackoverflow.com/a/22395580">dynamically scoped</a>, we can&rsquo;t do the same when a variable is accessed from the surrounding scope. In this case, we must access it by name. If we&rsquo;re assuming a stack-based virtual machine this would look something like so:</p>
<div class="highlight"><pre class="chroma"><code class="language-rust" data-lang="rust"><span class="k">enum</span> <span class="nc">OpCode</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">    </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="w">
</span><span class="w">    </span><span class="sd">/// Access a variable in the current function&#39;s scope.
</span><span class="sd"></span><span class="w">    </span><span class="n">PushVariableFromCurrentScope</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">        </span><span class="sd">/// The stack slot to access. If we have 4 variables called `a`, `b`,
</span><span class="sd"></span><span class="w">        </span><span class="sd">/// `c`, and `d`, we can access `a` with stack slot `0`, `b` with stack
</span><span class="sd"></span><span class="w">        </span><span class="sd">/// slot `1`, etc. This is much faster than looking up by name.
</span><span class="sd"></span><span class="w">        </span><span class="n">stack_slot</span>: <span class="kt">usize</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="p">},</span><span class="w">
</span><span class="w">    </span><span class="sd">/// Access a variable in the parent scope. Because this language is
</span><span class="sd"></span><span class="w">    </span><span class="sd">/// dynamically-scoped we can&#39;t apply the same optimisations as if we had
</span><span class="sd"></span><span class="w">    </span><span class="sd">/// made it lexically scoped. As a result, we must look up the variable
</span><span class="sd"></span><span class="w">    </span><span class="sd">/// by name each time.
</span><span class="sd"></span><span class="w">    </span><span class="n">PushVariableFromSurroundingScope</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="w">        </span><span class="sd">/// The name of the variable. This would be `&amp;str` but I&#39;ve chosen
</span><span class="sd"></span><span class="w">        </span><span class="sd">/// `String` here to illustrate my point.
</span><span class="sd"></span><span class="w">        </span><span class="n">variable_name</span>: <span class="nb">String</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="p">}</span><span class="w">
</span><span class="w">
</span><span class="w">    </span><span class="c1">// ..snip..
</span><span class="c1"></span><span class="p">}</span></code></pre></div>
<p>Then you can convert function calls to jumps (first-class functions would get converted to passing function pointers) and the entire <code>eval</code> function becomes one loop. Much faster than recursive calls. Probably you won&rsquo;t finish this task by the end of the session but hey, writing compilers is fun.</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:often-said">By me. So far I haven&rsquo;t got it to catch on.
 <a class="footnote-return" href="#fnref:often-said"><sup>[return]</sup></a></li>
<li id="fn:rawtable">Actually <code>HashMap</code> is a wrapper around <code>RawTable</code> and so you&rsquo;ll see <code>RawTable</code> in the callee map, <code>HashMap</code> has been totally inlined at this point and so doesn&rsquo;t appear in the stack trace. If you see a <code>std</code> item that you don&rsquo;t recognise then try looking it up in Rust&rsquo;s <a href="https://doc.rust-lang.org/1.9.0/std/">stdlib documentation</a>. Unfortunately, that doesn&rsquo;t help here (<code>RawTable</code> is private) but it will help for many other types. For example, the &ldquo;raw&rdquo; inner type for <code>Vec</code> <a href="https://doc.rust-lang.org/1.9.0/alloc/raw_vec/struct.RawVec.html">is public and listed in the stdlib docs</a>.
 <a class="footnote-return" href="#fnref:rawtable"><sup>[return]</sup></a></li>
<li id="fn:flapjacks">This example works with American or British flapjacks but just to make sure we&rsquo;ve all equally confused, let&rsquo;s say that it&rsquo;s a new kind of flapjack that combines the benefits of both British and American kinds.
 <a class="footnote-return" href="#fnref:flapjacks"><sup>[return]</sup></a></li>
<li id="fn:hashmap">The real libstd <code>HashMap</code> is <em>much</em> more complicated than this, using a cool algorithm known as &ldquo;Robin Hood hashing&rdquo; - because it steals from the &ldquo;rich&rdquo; (the full buckets) and gives to the &ldquo;poor&rdquo; (the less-full buckets). There&rsquo;s a really good explanation of this algorithm on the always-fantastic <a href="https://accidentallyquadratic.tumblr.com/post/153545455987/rust-hash-iteration-reinsertion">Accidentally Quadratic blog</a>. For the purposes of this explanation though, this simplistic implementation is good enough.
 <a class="footnote-return" href="#fnref:hashmap"><sup>[return]</sup></a></li>
</ol>
</div>

</div>

<footer>
	<p>Â© 2017-2018, all rights reserved.</a>
</footer>
</body>
</html>
